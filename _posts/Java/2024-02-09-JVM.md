---
title:  "JVM"
date:   2024-02-09 20:27:00
categories: ['Java']
tags: ['Java']
---

{% include toc title="Index" %}

Java code conpiles to byte code (.class file) which then runs (interpretted at runtime) in JVM.

Write code once and run it on any hardware consistently.

For C language, the code is directly compiled to native machine code

# JIT - Just In Time compilation

The Java Virtual Machine has a feature called Just in Time compilation.

The JVM will monitor which branches of code are run the most often, which methods or parts of methods, specifically loops
are executed the most frequently.

So code execution would be speed-ed up if that method/part of method was compiled to native machine code and JVM will then do so.

So some of our application is being run 
* in interpreted mode as bytecode and 
* some is no longer bytecode but is running as compiled native machine code.

This process of native compilation is completely transparent to the user, but it has an important implication

Your code will generally run faster the longer it is left to run.

That's because the virtual machine can profile your code and work out which bits of it could be optimized

by compiling them to native machine code.

# Compiler Flags

`-XX:+PrintCompilation`

* -XX means it's an advanced option
* a plus or a minus indicates if we want the option to be switched on or off 
* and then the option name in `SentenceCase`

```log
50   31     n 0       java.lang.System::arraycopy (native)   (static)
56   19       3       java.lang.Integer::valueOf (32 bytes)
56   20       3       java.lang.Number::<init> (5 bytes)
56   21       3       java.lang.Integer::<init> (10 bytes)
57   23 %     4       nitin.performance.PrimeNumbers::isPrime @ 2 (35 bytes)
57   22       1       java.util.ArrayList::size (5 bytes)
57   24       3       nitin.performance.PrimeNumbers::getNextPrimeAbove (40 bytes)
```

column 1 is time in milliseconds since the VM Started<br>
column 2 is sequence of execution <br>
`n` means Native method <br>
`s` means it's a synchronized method <br>
`%` means the code is in code-cache for optimal performance <br>
Next column is `1,2,3,4` indicating Compilation level (`C1 -> Native Level 1,2,3` & `C2 -> Native Level 4`) <br>
`made not entrant` means <br>


`-XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation`
* creates a log file like `hotspot_pid1234.log`

# C1 and C2 compilers

The **HotSpot virtual machine** (since Java version 1.3) contains two conventional JIT-compilers: 
* the client compiler, also called C1 
  * C1 is designed to run faster and produce less optimized code,
  * is a better fit for desktop applications, since its faster
* the server compiler, called opto or C2.
  * C2 takes a little more time to run but produces a better-optimized code.
  * C2 has been extremely optimized and produces code that can compete with C++
  * is better for long-running server applications that can spend more time on the JIT compilation

#  Tiered Compilation
The Java program, compiled by javac, starts its execution in an interpreted mode. 
The JVM tracks each frequently called method and compiles them using C1 for the compilation. 
The HotSpot still keeps an eye on the future and frequent calls and based on frequency, the JVM will recompile using C2.

The default strategy used by the HotSpot is called tiered compilation.

`-client` - to prevent C2 compiler to kick in if needed.

`-server`

`-d64`


`-XX:-TieredCompilation` : Turn off the Tiered Compilation

# Native Compilation tuning 

```shell
java -XX:+PrintFlagsFinal
```
Check the 

`CICompilerCount` -  how many threads are available to run the compiling process

`CompileThreshold` - the number of times a method/code needs to run before it is natively compiled
```log
bool C1ProfileVirtualCalls                    = true                                   {C2 product} {default}
bool C1UpdateMethodData                       = true                                   {C2 product} {default}
intx CICompilerCount                          = 12                                        {product} {ergonomic}
bool CICompilerCountPerCPU                    = true                                      {product} {default}
intx CompileThreshold                         = 10000                                  {pd product} {default}
```
The same can be found out using jinfo

Run the `jps` command to see the java processes
```shell
jps
11440 GradleDaemon
1692 Main
17342 Jps
```

Check jshdb jinfo vs jinfo
{: .notice--danger}

```shell
jinfo --flag CICompilerCount 1692
```

`-XX:CICompilerCount=n`

`-XX:CompileThreshold=n`

# Profiling the code

The virtual machine decides which level of compilation to apply to a particular block of code based on **how often it is being run**
and how complex or time-consuming it is.

the higher the number, the more profiled the code has been.

If the code has been called enough times, then we reach level four and the C2 compiler has been
used instead.

And this means that our code is even more optimized than when it was compiled using the C1 compiler

and the Java virtual machine can actually decide.

# Tuning the code cache

`-XX:+PrintCodeCache`
If the code cache is full, the warning message is `code cache is full, compiler has been disabled.`


```log
CodeHeap 'non-profiled nmethods': size=119168Kb used=12Kb max_used=12Kb free=119155Kb
 bounds [0x0000000121fe8000, 0x0000000122258000, 0x0000000129448000]
 
CodeHeap 'profiled nmethods': size=119164Kb used=34Kb max_used=34Kb free=119129Kb
 bounds [0x000000011a448000, 0x000000011a6b8000, 0x00000001218a7000]

CodeHeap 'non-nmethods': size=7428Kb used=1152Kb max_used=1169Kb free=6275Kb
 bounds [0x00000001218a7000, 0x0000000121b17000, 0x0000000121fe8000]

total_blobs=332 nmethods=33 adapters=206

compilation: enabled
stopped_count=0, restarted_count=0 full_count=0
```


We can change the code cache size with three different flags.

`InitialCodeCacheSize` is the size of the code cache when the application starts.
The default size varies based on available memory, but it's often around about 160kB.

`ReservedCodeCacheSize` is the maximum size of the code cache. In other words, the code cache can grow over time 
**up to the size** of the reserved code cache.

`CodeCacheExpansionSize` dictates how quickly the code cache should grow as it gets full. How much extra space should be 
added each time the code cache is grown

Example
```shell
java -XX:ReservedCodeCacheSize=150M -XX:+PrintCodeCache RunProgram

CodeCache: size=153600Kb used=1197Kb max_used=1211Kb free=152402Kb
 bounds [0x0000000113d48000, 0x0000000113fb8000, 0x000000011d348000]
 total_blobs=330 nmethods=31 adapters=206
 compilation: enabled
 
stopped_count=0, restarted_count=0 full_count=0
```

# Remotely manage codeCache using Jconsole

From local Java installation, invoke the Jconsole
```shell
cd /usr/bin
jconsole
2024-02-10 00:16:58.371 jconsole[16258:688137] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.

```
![jconsole.png](..%2F..%2Fassets%2Fimages%2Fjconsole.png)

![jconsole-log.png](..%2F..%2Fassets%2Fimages%2Fjconsole-log.png)

# 32 bit JVM vs 64 bit JVM

| 32 bit JVM                        | 64 bit JVM                                             | 
|:----------------------------------|:-------------------------------------------------------|      
| Might be faster if heapSize < 3GB | Might be faster if heavy use of longs & doubles        |
| Max Heap Size = 4GB               | Max Heap size - OS Dependent - Necessary if heap > 4GB |
| Client compiler Only (C1, Faster) | Client & Server Compilers (C1 & C2)                    |


based around the fact that each pointer to an object in memory will be smaller due to 32 bit size pointer<br>
It will be 32 bits rather than 64 bits. And so manipulating these pointers will be quicker.)  


The important point here is that for smaller applications, don't just pick the 64 bit version of the  Java virtual machine 
First, test the performance on both 32 bit and 64 bit JVM
You might find you get better performance with the 32 bit JVM in case you're interested.

# Tuning JVM Flags

String Pool is implements using a hashmap

A hash code is calculated by JVM and the string is put into the map

A standard hash map starts with just 16 buckets, but it grows over time.

`-XX:+PrintStringTableStatistics`
`-XX:StringTableSize=120120`

`-XX:MaxHeapSize=1g` OR `-Xmx1g`
`-XX:InitialHeapSize=4g` OR `-Xms4g`

`-XX:+UnlockDiagnosticVMOptions`
`-XX:+PrintFlagsFinal`


`-XX:+PrintStringTableStatistics -XX:StringTableSize=999999 -Xmx1g -Xms4g`
```log
StringTable statistics:
Number of buckets       :     65536 =    524288 bytes, each 8
Number of entries       :         7 =       112 bytes, each 16
Number of literals      :         7 =       488 bytes, avg  69.000
Total footprint         :           =    524888 bytes
Average bucket size     :     0.000
Variance of bucket size :     0.000
Std. dev. of bucket size:     0.010
Maximum bucket size     :         1

Shared String Table statistics:
Number of buckets       :      1920
Number of entries       :      7438
Maximum bucket size     :        11
```

`-XX:+HeapDumpOnOutOfMemoryError`
`-XX:HeapDumpPath=<>`